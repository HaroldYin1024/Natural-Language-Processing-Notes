{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modelling\n",
    "## Unsupervised learning of topics in a text\n",
    "### using Latent Dirchlet Allocation (via sklearn)\n",
    "Topic modelling can be thought of as dimensionality reduction:  \n",
    "Documents are represented as sets of topics  \n",
    "Each topic has a weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import csv\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import string\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use CountVectorizer to turn the docs into vectors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the stemmer\n",
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_csv(csv_file):\n",
    "    with open(csv_file, 'r', encoding='utf-8') as fp:\n",
    "        reader = csv.reader(fp, delimiter=',', quotechar='\"')\n",
    "        data_read = [row for row in reader]\n",
    "    return data_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_file_path = \"stopwords.csv\"\n",
    "\n",
    "def get_stopwords(path=stopwords_file_path):\n",
    "    stopwords = read_in_csv(path)\n",
    "    stopwords = [word[0] for word in stopwords]\n",
    "    stemmed_stopwords = [stemmer.stem(word) for word in stopwords]\n",
    "    stopwords = stopwords + stemmed_stopwords\n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in our data\n",
    "stopwords = get_stopwords(stopwords_file_path)\n",
    "bbc_dataset = \"bbc-text.csv\"\n",
    "\n",
    "# helper functions\n",
    "def tokenize_and_stem(sentence):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    filtered_tokens = [t for t in tokens if t not in stopwords and t not in string.punctuation and re.search('[a-zA-Z]', t)]\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We’ll use a public dataset from the BBC comprised of 2,225 articles  \n",
    "Each labeled under one of 5 categories: business, entertainment, politics, sport or tech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the documents into vectors\n",
    "def create_count_vectorizer(documents):\n",
    "    count_vectorizer = CountVectorizer(stop_words=stopwords, tokenizer=tokenize_and_stem, max_features=1500)\n",
    "    data = count_vectorizer.fit_transform(documents)\n",
    "    return (count_vectorizer, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unwanted characters (keep just words and spaces)\n",
    "def clean_data(df):\n",
    "    df['text'] = df['text'].apply(lambda x: re.sub(r'[^\\w\\s]', ' ', x))\n",
    "    df['text'] = df['text'].apply(lambda x: re.sub(r'\\d', '', x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the LDA model (note that usually num_topics is unknown)\n",
    "def create_and_fit_lda(data, num_topics):\n",
    "    lda = LDA(n_components=num_topics, n_jobs=-1)\n",
    "    lda.fit(data)\n",
    "    return lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify & print the most common topic words\n",
    "def get_most_common_words_for_topics(model, vectorizer, n_top_words):\n",
    "    words = vectorizer.get_feature_names()\n",
    "    word_dict = {}\n",
    "    for topic_index, topic in enumerate(model.components_):\n",
    "        this_topic_words = [words[i] for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "        word_dict[topic_index] = this_topic_words\n",
    "    return word_dict\n",
    "\n",
    "def print_topic_words(word_dict):\n",
    "    for key in word_dict.keys():\n",
    "        print(f\"Topic {key}\")\n",
    "        print(\"\\t\", word_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data, clean it, get text\n",
    "df = pd.read_csv(bbc_dataset)\n",
    "df = clean_data(df)\n",
    "documents = df['text']\n",
    "\n",
    "# set number of topics (note that usually this is unknown)\n",
    "number_topics = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Extract one of the categories  \n",
    "Select a particular category from the dataframe, e.g. tech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['category']=='tech']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tech</td>\n",
       "      <td>games maker fights for survival one of britain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tech</td>\n",
       "      <td>security warning over  fbi virus  the us feder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tech</td>\n",
       "      <td>halo  heralds traffic explosion the growing po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>tech</td>\n",
       "      <td>mobile audio enters new dimension as mobile ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2204</th>\n",
       "      <td>tech</td>\n",
       "      <td>argonaut founder rebuilds empire jez san  the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>tech</td>\n",
       "      <td>california sets fines for spyware the makers o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2213</th>\n",
       "      <td>tech</td>\n",
       "      <td>progress on new internet domains by early  the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>tech</td>\n",
       "      <td>junk e mails on relentless rise spam traffic i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2217</th>\n",
       "      <td>tech</td>\n",
       "      <td>rings of steel combat net attacks gambling is ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>401 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     category                                               text\n",
       "0        tech  tv future in the hands of viewers with home th...\n",
       "19       tech  games maker fights for survival one of britain...\n",
       "20       tech  security warning over  fbi virus  the us feder...\n",
       "21       tech  halo  heralds traffic explosion the growing po...\n",
       "24       tech  mobile audio enters new dimension as mobile ph...\n",
       "...       ...                                                ...\n",
       "2204     tech  argonaut founder rebuilds empire jez san  the ...\n",
       "2207     tech  california sets fines for spyware the makers o...\n",
       "2213     tech  progress on new internet domains by early  the...\n",
       "2215     tech  junk e mails on relentless rise spam traffic i...\n",
       "2217     tech  rings of steel combat net attacks gambling is ...\n",
       "\n",
       "[401 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the output\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vectorizer & model\n",
    "(vectorizer, data) = create_count_vectorizer(documents)\n",
    "lda = create_and_fit_lda(data, number_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Inspect the results  \n",
    "Are they coherent? Do they seem to be different topics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0\n",
      "\t ['mobil', 'phone', 'use', 'peopl', 'technolog', 'make', 'servic', 'camera', 'network', 'year']\n",
      "Topic 1\n",
      "\t ['game', 'search', 'play', 'peopl', 'time', 'get', 'use', 'world', 'year', 'site']\n",
      "Topic 2\n",
      "\t ['music', 'peopl', 'servic', 'file', 'appl', 'digit', 'player', 'net', 'use', 'gadget']\n",
      "Topic 3\n",
      "\t ['technolog', 'tv', 'digit', 'high', 'video', 'peopl', 'year', 'broadband', 'show', 'content']\n",
      "Topic 4\n",
      "\t ['softwar', 'use', 'secur', 'virus', 'mail', 'program', 'firm', 'user', 'e', 'microsoft']\n"
     ]
    }
   ],
   "source": [
    "# inspect the contents of the topics\n",
    "topic_words = get_most_common_words_for_topics(lda, vectorizer, 10)\n",
    "print_topic_words(topic_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_new_example(lda,vect,example):\n",
    "    vectorized=vect.transform([example])\n",
    "    topic=lda.transform(vectorized)\n",
    "    print(topic)\n",
    "    return topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Try a different category  \n",
    "Select a different category from the dataframe, e.g. sport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Inspect the results  \n",
    "Are they coherent? Do they seem to be different topics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Try different values of N  \n",
    "Return to Step 1 and repeat the process with a different number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
